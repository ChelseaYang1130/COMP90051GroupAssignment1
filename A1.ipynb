{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2277c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb18b2",
   "metadata": {},
   "source": [
    "# data proceessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d0bcd4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = \"https://raw.githubusercontent.com/ChelseaYang1130/COMP90051GroupAssignment1/JingYang/train.json\"\n",
    "test_url = \"https://raw.githubusercontent.com/ChelseaYang1130/COMP90051GroupAssignment1/JingYang/test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "976b2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def vectorizer(single_paper):\n",
    "    counter=collections.Counter(single_paper)\n",
    "    vectors = {i : 0 for i in range(500)}\n",
    "    for key in counter.keys():\n",
    "        vectors[key] = counter[key]\n",
    "    return list(vectors.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b4ef41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(url):\n",
    "    data = []\n",
    "    response = urlopen(train_url)\n",
    "\n",
    "    for line in response:\n",
    "        data.append(json.loads(line))\n",
    "        \n",
    "    paper = []\n",
    "    for i in range(len(data[0])):\n",
    "        paper.append(data[0][str(i)])\n",
    "        \n",
    "    print(\"The information of 1st paper:\",paper[0])\n",
    "    \n",
    "    return paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5cd8557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The information of 1st paper: {'venue': '', 'keywords': [64, 1, 322, 134, 136, 396, 270, 144, 476, 481, 165, 39, 361, 43, 177, 308, 310, 118, 187, 127], 'year': 2017, 'author': [1605, 759]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'venue': 0,\n",
       " 'keywords': [258,\n",
       "  260,\n",
       "  389,\n",
       "  261,\n",
       "  390,\n",
       "  396,\n",
       "  400,\n",
       "  17,\n",
       "  146,\n",
       "  274,\n",
       "  21,\n",
       "  283,\n",
       "  156,\n",
       "  291,\n",
       "  43,\n",
       "  44,\n",
       "  177,\n",
       "  436,\n",
       "  437,\n",
       "  182,\n",
       "  185,\n",
       "  189,\n",
       "  318,\n",
       "  319,\n",
       "  450,\n",
       "  195,\n",
       "  452,\n",
       "  201,\n",
       "  331,\n",
       "  332,\n",
       "  461,\n",
       "  342,\n",
       "  87,\n",
       "  476,\n",
       "  100,\n",
       "  485,\n",
       "  492,\n",
       "  493,\n",
       "  494,\n",
       "  368,\n",
       "  373,\n",
       "  118,\n",
       "  254],\n",
       " 'year': 2013,\n",
       " 'author': [2182]}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_data = read_data(train_url)\n",
    "paper_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "defd28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data):\n",
    "    authors = []\n",
    "    keywords = []\n",
    "    mat = []\n",
    "\n",
    "    for p in paper_data:\n",
    "        for i in range(len(p['author'])):\n",
    "            authors.append(str(p['author'][i]))\n",
    "            keywords.append(p['keywords'])\n",
    "\n",
    "            mat.append(vectorizer(p['keywords']))\n",
    "    return authors, keywords, np.matrix(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a55dab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors, keywords, vectors = extract_data(paper_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "29a66f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 500)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ae4cc97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cca66398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b65f8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, authors, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "57e75de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelseayeung/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "94320592",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7aae7cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelseayeung/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/by/tkz5lcyx213g4fb695nwr3n40000gn/T/ipykernel_13365/3367516537.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    534\u001b[0m                              \"instead\".format(max_fpr))\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[1;32m    538\u001b[0m                                          multi_class, average, sample_weight)\n",
      "\u001b[0;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080698f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
